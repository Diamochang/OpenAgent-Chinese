version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: open_agent
    restart: unless-stopped
    env_file:
      - .env
    depends_on:
      ollama_init:
        condition: service_completed_successfully
    networks:
      - ollama-docker

  ollama:
    volumes:
      - ollama_data:/root/.ollama
    container_name: ollama_v2
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - "9006:11434"
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama_init:
    image: curlimages/curl:latest
    container_name: ollama_init
    depends_on:
      - ollama
    entrypoint: [ "/bin/sh", "-c", "curl -X POST -H 'Content-Type: application/json' -d '{\"name\": \"${MODEL_NAME}\"}' http://ollama:11434/api/pull" ]
    environment:
      - MODEL_NAME=llama3
    networks:
      - ollama-docker

  vec_db:
    image: pgvector/pgvector:pg16
    container_name: vec_db_v2
    restart: unless-stopped
    networks:
      - ollama-docker
    environment:
      POSTGRES_USER: langchain
      POSTGRES_PASSWORD: langchain
      POSTGRES_DB: langchain
    ports:
      - "6433:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data

  biz_db:
    image: postgres:14-alpine
    container_name: biz_db_v2
    restart: unless-stopped
    networks:
      - ollama-docker
    ports:
      - "6432:5432"
    env_file:
      - .env
    environment:
      POSTGRES_PASSWORD: password
    volumes:
      - pg_data:/var/lib/postgresql/data

volumes:
  pgvector_data:
  pg_data:
  ollama_data:

networks:
  ollama-docker:
    external: false
